{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1cecfb-f07a-4073-9230-52cbf1a1ee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import pipeline\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7d3e64-336f-4c7d-a022-4464e628a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Here's a simulated interview for a Software Engineer role:\\n\\n**Interviewer:** Hi Alice, thank you for coming in today. Can you start by telling me a little bit about your background and why you're interested in this Software Engineer role?\\n\\n**Alice Smith:** Yeah, sure. So, I have a degree in computer science, and I've been working in the field for about three years now. I'm interested in this role because I enjoy coding and problem-solving, and I think this company does some really interesting work.\\n\\n**Interviewer:** Great, thanks for sharing that. Can you walk me through your experience with a specific programming language? Let's say Java. How have you used Java in previous projects?\\n\\n**Alice Smith:** Um, I've used Java before...I think. I mean, I've written some Java code, but I don't really remember the specifics. I've worked on a few projects that used Java, but I didn't really have a leading role or anything.\\n\\n**Interviewer:** I see. In a software engineering role, being able to write high-quality, efficient code is crucial. Can you give me an example of a particularly challenging coding problem you've solved in the past? How did you approach it?\\n\\n**Alice Smith:** Well, there was this one time...I think it was a homework assignment or something. We had to implement a sorting algorithm, and I chose to use...um...merge sort, I think? I don't really remember the details, but it was a while ago.\\n\\n**Interviewer:** Merge sort is a good choice. But can you tell me more about the specifics of how you implemented it? For example, how did you handle edge cases or optimize the algorithm for performance?\\n\\n**Alice Smith:** (pauses) Honestly, I don't really remember. I mean, I wrote the code, but I don't recall the details of how I handled edge cases or anything like that.\\n\\n**Interviewer:** I understand that it's been a while since you wrote the code, but as a software engineer, being able to recall and explain the details of your work is important. Can you tell me about your experience with any specific software development methodologies, such as Agile or Scrum?\\n\\n**Alice Smith:** (nervously) Uh, I've heard of those...I think? We used something like that on a project once, but I don't really remember the specifics. I'm sure it's not that important.\\n\\n**Interviewer:** (pausing, considering whether to continue the line of questioning) Okay, let's move on to some technical questions. Can you explain the difference between a stack and a queue data structure?\\n\\n**Alice Smith:** (hesitates) Um...I think a stack is like...a pile of plates? And a queue is like...a line of people?\\n\\n**Interviewer:** (surprised) That's not quite correct. A stack is a last-in, first-out data structure, whereas a queue is a first-in, first-out data structure. Let's move on to the next question.\\n\\n**Interviewer:** (quickly wrapping up the interview) Well, Alice, thank you for coming in today. Do you have any questions for me?\\n\\n**Alice Smith:** (relieved) Yeah, actually. What's the company culture like here?\\n\\n**Interviewer:** (smiling politely) That's a great question. We're a collaborative and innovative team. We're always looking for ways to improve our processes and technology. We'll be in touch soon to let you know about next steps.\\n\\n**Interviewer:** (to themselves) Not sure if this candidate is a good fit for the role...',\n",
      "       'Name', 'Role', 'Transcript', 'Resume', 'Performance (select/reject)',\n",
      "       'Reason for decision', 'Job Description', 'ID', 'decision',\n",
      "       'Unnamed: 0', 'num_words_in_transcript', 'similarity',\n",
      "       'job_desc_cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ad536-8873-4e7b-9b25-d7442686389a",
   "metadata": {},
   "source": [
    "# Resume screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "909b690a-bdbb-470e-af8a-c56fc1f655bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID               Role  similarity  decision  job_desc_cluster\n",
      "0        auto_1  Software Engineer    0.224841  Rejected                 2\n",
      "1        auto_2  Software Engineer    0.223900  Rejected                 2\n",
      "2        auto_3     Data Scientist    0.391478  Selected                 2\n",
      "3        auto_4  Software Engineer    0.272689  Rejected                 2\n",
      "4        auto_5      Data Engineer    0.371126  Selected                 2\n",
      "...         ...                ...         ...       ...               ...\n",
      "3169   ananba44      data engineer    0.328732  Selected                 4\n",
      "3170  diyasi576    product manager    0.289358  Selected                 4\n",
      "3171  harska507        ui engineer    0.471586  Selected                 0\n",
      "3172  kabich225  software engineer    0.329432  Selected                 4\n",
      "3173  aditsi182  software engineer    0.202067  Selected                 4\n",
      "\n",
      "[3174 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load your dataset\n",
    "# Replace 'your_dataset.csv' with your actual dataset file\n",
    "combined_df = pd.read_csv(\"combined_cleaned_dataset.csv\")\n",
    "\n",
    "# Step 1: Role-specific thresholds for screening\n",
    "role_thresholds = {\n",
    "    \"Software Engineer\": 0.4,\n",
    "    \"Data Scientist\": 0.2,\n",
    "    \"UI Engineer\": None,  # No threshold\n",
    "}\n",
    "\n",
    "# Step 2: Function to calculate TF-IDF and cosine similarity\n",
    "def calculate_similarity(df, job_col, resume_col):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    # Fit the TF-IDF vectorizer on both job descriptions and resumes\n",
    "    vectorizer.fit(pd.concat([df[job_col], df[resume_col]]))\n",
    "\n",
    "    job_desc_vector = vectorizer.transform(df[job_col])\n",
    "    resume_vector = vectorizer.transform(df[resume_col])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    df['similarity'] = cosine_similarity(job_desc_vector, resume_vector).diagonal()\n",
    "    return df\n",
    "\n",
    "# Step 3: Apply role-specific thresholds for screening\n",
    "def screen_resumes(df, role_thresholds):\n",
    "    decisions = []\n",
    "    for _, row in df.iterrows():\n",
    "        role = row['Role']\n",
    "        similarity = row['similarity']\n",
    "        threshold = role_thresholds.get(role, None)\n",
    "        \n",
    "        # Apply decision logic\n",
    "        if threshold is None or similarity >= threshold:\n",
    "            decisions.append(\"Selected\")\n",
    "        else:\n",
    "            decisions.append(\"Rejected\")\n",
    "    \n",
    "    df['decision'] = decisions\n",
    "    return df\n",
    "\n",
    "# Step 4: Add clustering for job descriptions (optional)\n",
    "def cluster_job_descriptions(df, job_col, n_clusters=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    X = vectorizer.fit_transform(df[job_col])\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['job_desc_cluster'] = kmeans.fit_predict(X)\n",
    "    return df\n",
    "\n",
    "# Step 5: Execute the workflow\n",
    "combined_df = calculate_similarity(combined_df, 'Job Description', 'Resume')\n",
    "combined_df = screen_resumes(combined_df, role_thresholds)\n",
    "combined_df = cluster_job_descriptions(combined_df, 'Job Description')\n",
    "\n",
    "# Handle missing IDs\n",
    "\n",
    "combined_df['ID'] = combined_df['ID'].fillna('').astype(str)\n",
    "missing_ids = combined_df['ID'] == ''\n",
    "combined_df.loc[missing_ids, 'ID'] = [f'auto_{i}' for i in range(1, missing_ids.sum() + 1)]\n",
    "\n",
    "\n",
    "# Save and display results\n",
    "combined_df.to_csv('resume_screening_results.csv', index=False)\n",
    "print(combined_df[['ID', 'Role', 'similarity', 'decision', 'job_desc_cluster']])\n",
    "\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "#combined_df.to_csv('resume_screening_results.csv', index=False)\n",
    "\n",
    "# Display the output\n",
    "#print(combined_df[['ID', 'Role', 'similarity', 'decision', 'job_desc_cluster']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef2d2c9-8678-4e44-9d41-eb10a367da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision\n",
      "Selected    2823\n",
      "Rejected     351\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['decision'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12d4a0d-da4c-4eb9-b82c-11d28c7bc745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role                          decision\n",
      "AI Engineer                   Selected     13\n",
      "Business Analyst              Selected     11\n",
      "Cloud Architect               Selected      8\n",
      "Content Writer                Selected      5\n",
      "Cybersecurity Specialist      Selected      9\n",
      "Data Analyst                  Selected     78\n",
      "Data Engineer                 Selected    192\n",
      "Data Scientist                Selected    163\n",
      "                              Rejected    129\n",
      "Database Administrator        Selected      9\n",
      "DevOps Engineer               Selected     16\n",
      "Digital Marketing Specialist  Selected     14\n",
      "Game Developer                Selected     10\n",
      "Graphic Designer              Selected     15\n",
      "HR Specialist                 Selected     12\n",
      "Machine Learning Engineer     Selected     13\n",
      "Mobile App Developer          Selected      7\n",
      "Network Engineer              Selected     16\n",
      "Product Manager               Selected    203\n",
      "Project Manager               Selected     56\n",
      "Software Developer            Selected     66\n",
      "Software Engineer             Rejected    222\n",
      "                              Selected      3\n",
      "System Administrator          Selected      5\n",
      "UI Designer                   Selected     71\n",
      "UI Engineer                   Selected    147\n",
      "UI/UX Designer                Selected      7\n",
      "data analyst                  Selected    183\n",
      "data engineer                 Selected    307\n",
      "data scientist                Selected    287\n",
      "product manager               Selected    303\n",
      "software engineer             Selected    307\n",
      "ui designer                   Selected    155\n",
      "ui engineer                   Selected    132\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.groupby('Role')['decision'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d569986e-4466-45c2-8f68-e6b01e80d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role\n",
      "AI Engineer                     0.568689\n",
      "Business Analyst                0.457339\n",
      "Cloud Architect                 0.561371\n",
      "Content Writer                  0.731989\n",
      "Cybersecurity Specialist        0.572296\n",
      "Data Analyst                    0.175903\n",
      "Data Engineer                   0.334887\n",
      "Data Scientist                  0.251659\n",
      "Database Administrator          0.572761\n",
      "DevOps Engineer                 0.401137\n",
      "Digital Marketing Specialist    0.616506\n",
      "Game Developer                  0.606549\n",
      "Graphic Designer                0.423924\n",
      "HR Specialist                   0.622331\n",
      "Machine Learning Engineer       0.429377\n",
      "Mobile App Developer            0.517457\n",
      "Network Engineer                0.676279\n",
      "Product Manager                 0.397590\n",
      "Project Manager                 0.254725\n",
      "Software Developer              0.069231\n",
      "Software Engineer               0.221384\n",
      "System Administrator            0.288313\n",
      "UI Designer                     0.183592\n",
      "UI Engineer                     0.379083\n",
      "UI/UX Designer                  0.503804\n",
      "data analyst                    0.053247\n",
      "data engineer                   0.161979\n",
      "data scientist                  0.161086\n",
      "product manager                 0.194933\n",
      "software engineer               0.150981\n",
      "ui designer                     0.051208\n",
      "ui engineer                     0.337979\n",
      "Name: similarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.groupby('Role')['similarity'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4039deb0-2fa9-4eaf-9084-e2dbe02536a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              count      mean       std       min       25%  \\\n",
      "Role                                                                          \n",
      "AI Engineer                    13.0  0.568689  0.078559  0.419033  0.527159   \n",
      "Business Analyst               11.0  0.457339  0.053995  0.360829  0.431233   \n",
      "Cloud Architect                 8.0  0.561371  0.027672  0.519828  0.538752   \n",
      "Content Writer                  5.0  0.731989  0.035762  0.673480  0.732680   \n",
      "Cybersecurity Specialist        9.0  0.572296  0.072154  0.420210  0.540033   \n",
      "Data Analyst                   78.0  0.175903  0.105870  0.063601  0.119622   \n",
      "Data Engineer                 192.0  0.334887  0.170651  0.062845  0.136596   \n",
      "Data Scientist                292.0  0.251659  0.117716  0.029431  0.153304   \n",
      "Database Administrator          9.0  0.572761  0.074955  0.414974  0.558291   \n",
      "DevOps Engineer                16.0  0.401137  0.058758  0.288414  0.361812   \n",
      "Digital Marketing Specialist   14.0  0.616506  0.055369  0.521942  0.583727   \n",
      "Game Developer                 10.0  0.606549  0.118061  0.425038  0.552315   \n",
      "Graphic Designer               15.0  0.423924  0.049571  0.332769  0.397926   \n",
      "HR Specialist                  12.0  0.622331  0.093486  0.447699  0.564909   \n",
      "Machine Learning Engineer      13.0  0.429377  0.060973  0.331774  0.402239   \n",
      "Mobile App Developer            7.0  0.517457  0.065756  0.400970  0.494972   \n",
      "Network Engineer               16.0  0.676279  0.068837  0.582382  0.620996   \n",
      "Product Manager               203.0  0.397590  0.165733  0.049016  0.218361   \n",
      "Project Manager                56.0  0.254725  0.049039  0.000000  0.230474   \n",
      "Software Developer             66.0  0.069231  0.032880  0.015261  0.047860   \n",
      "Software Engineer             225.0  0.221384  0.100149  0.025955  0.136310   \n",
      "System Administrator            5.0  0.288313  0.017306  0.258816  0.289949   \n",
      "UI Designer                    71.0  0.183592  0.049246  0.081517  0.148964   \n",
      "UI Engineer                   147.0  0.379083  0.097379  0.116116  0.314714   \n",
      "UI/UX Designer                  7.0  0.503804  0.063217  0.411230  0.466503   \n",
      "data analyst                  183.0  0.053247  0.032763  0.000000  0.031040   \n",
      "data engineer                 307.0  0.161979  0.137556  0.000000  0.037642   \n",
      "data scientist                287.0  0.161086  0.116982  0.000000  0.049984   \n",
      "product manager               303.0  0.194933  0.148626  0.001947  0.052219   \n",
      "software engineer             307.0  0.150981  0.100344  0.000000  0.061993   \n",
      "ui designer                   155.0  0.051208  0.034603  0.000000  0.024328   \n",
      "ui engineer                   132.0  0.337979  0.073374  0.179016  0.286038   \n",
      "\n",
      "                                   50%       75%       max  \n",
      "Role                                                        \n",
      "AI Engineer                   0.561721  0.635687  0.672327  \n",
      "Business Analyst              0.464535  0.483006  0.542208  \n",
      "Cloud Architect               0.562497  0.585234  0.595177  \n",
      "Content Writer                0.735319  0.749318  0.769146  \n",
      "Cybersecurity Specialist      0.594295  0.595856  0.660588  \n",
      "Data Analyst                  0.145042  0.185724  0.517505  \n",
      "Data Engineer                 0.385326  0.486173  0.618461  \n",
      "Data Scientist                0.227850  0.365009  0.516946  \n",
      "Database Administrator        0.568355  0.611224  0.684542  \n",
      "DevOps Engineer               0.381953  0.438155  0.516537  \n",
      "Digital Marketing Specialist  0.621818  0.650119  0.715122  \n",
      "Game Developer                0.621181  0.693163  0.769957  \n",
      "Graphic Designer              0.415065  0.450776  0.510195  \n",
      "HR Specialist                 0.605850  0.669958  0.775025  \n",
      "Machine Learning Engineer     0.419868  0.443460  0.574741  \n",
      "Mobile App Developer          0.526578  0.546087  0.612536  \n",
      "Network Engineer              0.669634  0.738737  0.790712  \n",
      "Product Manager               0.451134  0.538354  0.697838  \n",
      "Project Manager               0.259996  0.286067  0.337482  \n",
      "Software Developer            0.066545  0.085819  0.160431  \n",
      "Software Engineer             0.248850  0.289415  0.433450  \n",
      "System Administrator          0.292701  0.296143  0.303957  \n",
      "UI Designer                   0.178749  0.215840  0.300925  \n",
      "UI Engineer                   0.383378  0.446751  0.563469  \n",
      "UI/UX Designer                0.503153  0.544721  0.589798  \n",
      "data analyst                  0.047074  0.073764  0.191824  \n",
      "data engineer                 0.092011  0.280808  0.489034  \n",
      "data scientist                0.133119  0.267587  0.398232  \n",
      "product manager               0.138725  0.339126  0.472679  \n",
      "software engineer             0.127945  0.231745  0.418761  \n",
      "ui designer                   0.041884  0.073767  0.140352  \n",
      "ui engineer                   0.334113  0.384975  0.529868  \n",
      "             ID               Role  similarity  decision\n",
      "0        auto_1  Software Engineer    0.224841  Rejected\n",
      "1        auto_2  Software Engineer    0.223900  Rejected\n",
      "2        auto_3     Data Scientist    0.391478  Selected\n",
      "3        auto_4  Software Engineer    0.272689  Rejected\n",
      "4        auto_5      Data Engineer    0.371126  Selected\n",
      "...         ...                ...         ...       ...\n",
      "3169   ananba44      data engineer    0.328732  Selected\n",
      "3170  diyasi576    product manager    0.289358  Selected\n",
      "3171  harska507        ui engineer    0.471586  Selected\n",
      "3172  kabich225  software engineer    0.329432  Selected\n",
      "3173  aditsi182  software engineer    0.202067  Selected\n",
      "\n",
      "[3174 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Analyze Similarity Scores Across Roles\n",
    "role_similarity_stats = combined_df.groupby('Role')['similarity'].describe()\n",
    "print(role_similarity_stats)\n",
    "\n",
    "# Step 2: Define Role-Specific Thresholds Based on Analysis\n",
    "role_thresholds = {\n",
    "    'Software Engineer': 0.4,\n",
    "    'Data Scientist': 0.2,\n",
    "    'UI Engineer': None,  # No threshold\n",
    "    'Data Engineer': 0.3,\n",
    "    'Product Manager': 0.25,\n",
    "}\n",
    "\n",
    "# Step 3: Apply the Thresholds\n",
    "def apply_role_thresholds(row, thresholds):\n",
    "    role = row['Role']\n",
    "    similarity = row['similarity']\n",
    "    threshold = thresholds.get(role, None)\n",
    "    \n",
    "    # If no threshold, default to 'Selected'\n",
    "    if threshold is None:\n",
    "        return 'Selected'\n",
    "    return 'Selected' if similarity >= threshold else 'Rejected'\n",
    "\n",
    "combined_df['decision'] = combined_df.apply(\n",
    "    apply_role_thresholds, axis=1, thresholds=role_thresholds\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(combined_df[['ID', 'Role', 'similarity', 'decision']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "866594cd-94ca-4332-a417-2aec888ff5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Separate features and target\n",
    "X = combined_df.drop(['decision', 'ID'], axis=1, errors='ignore')\n",
    "y = combined_df['decision']\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Encode target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34bbe2cb-280e-4ae1-ac59-5d182f00f4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (2539, 11245), Test set size: (635, 11245)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "print(f\"Train set size: {X_train.shape}, Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3716bf67-3eea-404f-a299-574fea7ac4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually impute missing values in numeric and categorical columns\n",
    "X[numeric_cols] = X[numeric_cols].apply(lambda col: col.fillna(col.mean()))\n",
    "X[categorical_cols] = X[categorical_cols].apply(lambda col: col.fillna(col.mode()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa2263-a5d4-4cae-b211-ab8c4502bceb",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c22ab05-bf09-4442-aac2-3a7fab0eb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        98\n",
      "           1       1.00      0.99      0.99       537\n",
      "\n",
      "    accuracy                           0.99       635\n",
      "   macro avg       0.96      0.98      0.97       635\n",
      "weighted avg       0.99      0.99      0.99       635\n",
      "\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[ 96   2]\n",
      " [  7 530]]\n",
      "\n",
      "SVM Accuracy Score:\n",
      "0.9858267716535433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Re-run the train-test split and model training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nSVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nSVM Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ec647-3e8f-449d-a264-3dcbfb0d9e4d",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2233407d-0d6a-4b6b-a25e-11ea5d8cf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Save the SVM model\n",
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e380a1d8-6a13-4857-9d7e-d0ae2ffe2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'ID', 'Name', 'Role', 'Transcript',\n",
      "       'Resume', 'Reason for decision', 'Job Description',\n",
      "       'num_words_in_transcript'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "new_data = pd.read_excel('Copy of prediction_data.xlsx')  # Adjust the filename if needed\n",
    "\n",
    "# Display the columns of the new data\n",
    "print(new_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ebd62d-017b-4e20-80d3-f03b8f493ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1\n",
      " 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1\n",
      " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your training data available\n",
    "# Example: Replace this with your actual training data\n",
    "X_train = pd.DataFrame({\n",
    "    'Transcript': ['Interview went well', 'Candidate was not qualified', 'Strong skills in the area', 'Not a good fit for the role'],\n",
    "    'Job Description': ['Software Engineer role', 'Data Scientist role', 'Developer role', 'HR role']\n",
    "})\n",
    "\n",
    "y_train = [1, 0, 1, 0]  # Example labels for training (1: selected, 0: rejected)\n",
    "\n",
    "# Define your preprocessor (to use TF-IDF for text columns)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'Transcript'),  # Transform 'Transcript' column using TF-IDF\n",
    "        ('text2', TfidfVectorizer(), 'Job Description')  # Transform 'Job Description' column using TF-IDF\n",
    "    ])\n",
    "\n",
    "# Step 1: Fit the preprocessor using training data\n",
    "# Fit the preprocessor with the training dataset (X_train)\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Step 2: Create and train your SVM model in a pipeline (this combines the preprocessor and the model)\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svm', SVC(kernel='linear'))  # You can change the SVM model as needed\n",
    "])\n",
    "\n",
    "# Train the model with the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Load the new data (prediction data)\n",
    "# Example: Replace this with your actual new dataset for prediction\n",
    "# Correct the file path by putting it inside quotes\n",
    "import os\n",
    "# Ensure the current directory is correct (this should be the directory where your files are located)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Set the path for the prediction file (replace with the actual name of your file)\n",
    "current_dir = os.getcwd()\n",
    "prediction_file_path = os.path.join(current_dir, 'Copy of prediction_data (1).xlsx')\n",
    "new_data = pd.read_excel(prediction_file_path)\n",
    "\n",
    " # Ensure this path is correct\n",
    "\n",
    "# Step 4: Process new data (only transformation, not fitting again)\n",
    "# We don't need to fit the preprocessor again; we just transform the new data.\n",
    "X_new = new_data[['Transcript', 'Job Description']]  # Ensure new data contains the correct columns\n",
    "\n",
    "# Step 5: Make predictions using the trained model pipeline (which includes the fitted preprocessor)\n",
    "y_new_pred = model_pipeline.predict(X_new)\n",
    "\n",
    "# Step 6: Display the predictions\n",
    "print(\"Predictions:\", y_new_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1e5fe-8516-4537-ad82-ae3dc04d3f86",
   "metadata": {},
   "source": [
    "# '1'is for selection\n",
    "# '0' is for rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee3e63d7-f528-477e-8604-32cd49977407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Transcript  \\\n",
      "0  **lahar singh: software engineer candidate int...   \n",
      "1  interview transcript: data engineer position\\n...   \n",
      "2  **interview transcript: amisha bedi, data scie...   \n",
      "3  **interview transcript: product manager positi...   \n",
      "4  product manager interview transcript\\n\\ninterv...   \n",
      "\n",
      "                                     Job Description  Predictions  \n",
      "0  communicated ideas clearly and effectively., h...            1  \n",
      "1  we are looking for a skilled data engineer wit...            0  \n",
      "2  lacked key technical skills for the role., nee...            1  \n",
      "3  had impressive experience and qualifications.,...            0  \n",
      "4  we are looking for a skilled product manager w...            1  \n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already fitted your model (e.g., model_pipeline)\n",
    "# and that your preprocessor is included in the pipeline\n",
    "X_new = new_data[['Transcript', 'Job Description']]  # Make sure this contains the right columns\n",
    "predictions = model_pipeline.predict(X_new)  # Get predictions from the model\n",
    "\n",
    "# Now you can add predictions to your new_data\n",
    "new_data['Predictions'] = predictions\n",
    "\n",
    "# Visualize the results\n",
    "print(new_data[['Transcript', 'Job Description', 'Predictions']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd06cfbc-1d2d-4f15-8dc3-df5b216e4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        67\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming 'Actual Outcome' is the true label column in your new_data\n",
    "y_true = new_data['Predictions']\n",
    "\n",
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(y_true, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_true, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d77d2d-c843-4956-a518-4c6bbb564806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a new Excel file\n",
    "new_data.to_excel('predictions_output.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a5b11-8696-480a-a8b8-b7ef31ee5b73",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d4dd4bb-674b-45c5-83c8-d9e7226b7ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Candidates:\n",
      "    Unnamed: 0.1  Unnamed: 0          ID            Name               Role  \\\n",
      "0            514         537  rivash0038     lahar singh  software engineer   \n",
      "2           1408        1467  rivash0968     amisha bedi     data scientist   \n",
      "4            390         410   bradgr792   bradley gross    product manager   \n",
      "5           1045        1095  rivash0596   dhanvi raghav       data analyst   \n",
      "6           1481        1541   anangu781    ananya gupta    product manager   \n",
      "..           ...         ...         ...             ...                ...   \n",
      "93           338         354   stepro867  stephanie ross    product manager   \n",
      "94           414         434   crysga384  crystal garcia  software engineer   \n",
      "95          1380        1438  rivash0939    charvi verma  software engineer   \n",
      "97           961        1008  rivash0509      ehan naidu  software engineer   \n",
      "98           568         595  rivash0096   saanjh chopra  software engineer   \n",
      "\n",
      "                                           Transcript  \\\n",
      "0   **lahar singh: software engineer candidate int...   \n",
      "2   **interview transcript: amisha bedi, data scie...   \n",
      "4   product manager interview transcript\\n\\ninterv...   \n",
      "5   **interviewer:** rakesh patel, hiring manager,...   \n",
      "6   here is a realistic interview transcript for t...   \n",
      "..                                                ...   \n",
      "93  here is a simulated interview transcript for a...   \n",
      "94  software engineer interview transcript\\n\\ninte...   \n",
      "95  **interview transcript**\\n\\n**interviewer:** r...   \n",
      "97  **interview transcript: software engineer posi...   \n",
      "98  **interview transcript: saanjh chopra - softwa...   \n",
      "\n",
      "                                               Resume  \\\n",
      "0   **lahar singh**\\n**software engineer candidate...   \n",
      "2   **candidate profile: amisha bedi**\\n\\n**role:*...   \n",
      "4   here's a sample resume for bradley gross apply...   \n",
      "5   **dhanvi raghav**\\n**data analyst candidate**\\...   \n",
      "6   ananya gupta\\ncontact information:\\n\\n* email:...   \n",
      "..                                                ...   \n",
      "93  here's a sample resume for stephanie ross appl...   \n",
      "94  here's a sample resume for crystal garcia:\\n\\n...   \n",
      "95  **charvi verma**\\n**software engineer candidat...   \n",
      "97  **candidate profile: ehan naidu**\\n\\n**positio...   \n",
      "98  **candidate profile: saanjh chopra**\\n\\n**inte...   \n",
      "\n",
      "                                  Reason for decision  \\\n",
      "0   expected_experience : 9+ years, domains: e-com...   \n",
      "2   expected_experience : 6-8 years, domains: heal...   \n",
      "4                                        cultural fit   \n",
      "5   expected_experience : 3-5 years, domains: mark...   \n",
      "6                                        cultural fit   \n",
      "..                                                ...   \n",
      "93                                         experience   \n",
      "94                                       cultural fit   \n",
      "95  expected_experience : 3-5 years, domains: e-co...   \n",
      "97  expected_experience : 6-8 years, domains: e-co...   \n",
      "98  expected_experience : 6-8 years, domains: e-co...   \n",
      "\n",
      "                                      Job Description  \\\n",
      "0   communicated ideas clearly and effectively., h...   \n",
      "2   lacked key technical skills for the role., nee...   \n",
      "4   we are looking for a skilled product manager w...   \n",
      "5   showed great enthusiasm and potential for grow...   \n",
      "6   \\n        we are seeking a qualified product m...   \n",
      "..                                                ...   \n",
      "93  we are looking for a skilled product manager w...   \n",
      "94  we are looking for a skilled software engineer...   \n",
      "95  had impressive experience and qualifications.,...   \n",
      "97  lacked key technical skills for the role., str...   \n",
      "98  demonstrated limited understanding of job requ...   \n",
      "\n",
      "    num_words_in_transcript  Predictions  \n",
      "0                       956            1  \n",
      "2                       612            1  \n",
      "4                       665            1  \n",
      "5                       789            1  \n",
      "6                       657            1  \n",
      "..                      ...          ...  \n",
      "93                      563            1  \n",
      "94                      893            1  \n",
      "95                      961            1  \n",
      "97                      577            1  \n",
      "98                      827            1  \n",
      "\n",
      "[67 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter candidates predicted to be selected (assuming 1 means selected and 0 means rejected)\n",
    "selected_candidates = new_data[new_data['Predictions'] == 1]\n",
    "rejected_candidates = new_data[new_data['Predictions'] == 0]\n",
    "\n",
    "print('Selected Candidates:')\n",
    "print(selected_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2eb161-577e-4f98-b435-e5383a30bb4b",
   "metadata": {},
   "source": [
    "#  Automatic E-mail generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d278726-420a-40e0-aab0-59af9ebafaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to send email to nehabhardwaj3603@gmail.com: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials 98e67ed59e1d1-2f7ffa6b2bdsm5310558a91.25 - gsmtp')\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# Example function to send an email\n",
    "def send_email(receiver_email, subject, body):\n",
    "    sender_email = \"your_email@example.com\"  # Your email address\n",
    "    sender_password = \"your_password\"  # Your email password (consider using OAuth for security)\n",
    "\n",
    "    # Create the email headers and body\n",
    "    message = MIMEMultipart()\n",
    "    message['From'] = sender_email\n",
    "    message['To'] = receiver_email\n",
    "    message['Subject'] = subject\n",
    "\n",
    "    # Attach the body with the message\n",
    "    message.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    try:\n",
    "        # Connect to the mail server and send the email\n",
    "        with smtplib.SMTP('smtp.example.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, sender_password)\n",
    "            server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "        print(f\"Email sent to {receiver_email}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send email to {receiver_email}: {e}\")\n",
    "\n",
    "# 3. Filter the selected candidates from the predictions\n",
    "selected_candidates = new_data[new_data['Predictions'] == 'Selected']\n",
    "\n",
    "# 4. Generate automatic emails for the selected candidates\n",
    "# You would replace 'candidate_emails' with a list of emails (if available)\n",
    "# For this case, I'll use placeholder email addresses:\n",
    "\n",
    "candidate_emails = {\n",
    "    'Candidate 1': 'candidate1@example.com',\n",
    "    'Candidate 2': 'candidate2@example.com',\n",
    "    'Candidate 3': 'candidate3@example.com',\n",
    "    # Add more candidates and emails here\n",
    "}\n",
    "\n",
    "subject = \"Congratulations on Your Job Interview\"\n",
    "body_template = \"\"\"\n",
    "Dear {name},\n",
    "\n",
    "We are pleased to inform you that you have been selected for the interview process.\n",
    "\n",
    "Best regards,\n",
    "Your Company\n",
    "\"\"\"\n",
    "\n",
    "# Iterate through the selected candidates\n",
    "for _, candidate in selected_candidates.iterrows():\n",
    "    candidate_name = candidate['Name']\n",
    "    if candidate_name in candidate_emails:\n",
    "        receiver_email = candidate_emails[candidate_name]\n",
    "        body = body_template.format(name=candidate_name)\n",
    "        send_email(receiver_email, subject, body)\n",
    "#Assuming Neha has been selected, and you are sending the email:\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# SMTP server configuration\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "smtp_port = 587\n",
    "sender_email = \"your_email@gmail.com\"  # Your email address\n",
    "sender_password = \"your_email_password\"  # Your email password\n",
    "\n",
    "# Recipient email address (Neha's email)\n",
    "receiver_email = \"nehabhardwaj3603@gmail.com\"\n",
    "\n",
    "# Create the email content\n",
    "subject = \"Congratulations on Your Job Interview\"\n",
    "body = \"\"\"\n",
    "Dear Neha,\n",
    "\n",
    "We are pleased to inform you that you have been selected for the interview process at Our Company. \n",
    "We will reach out to you shortly with further details.\n",
    "\n",
    "Best regards,\n",
    "Your Company\n",
    "\"\"\"\n",
    "\n",
    "# Create the email\n",
    "message = MIMEMultipart()\n",
    "message[\"From\"] = sender_email\n",
    "message[\"To\"] = receiver_email\n",
    "message[\"Subject\"] = subject\n",
    "\n",
    "# Attach the body to the email\n",
    "message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "# Send the email\n",
    "try:\n",
    "    # Set up the SMTP server and send the email\n",
    "    server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "    server.starttls()  # Secure the connection\n",
    "    server.login(sender_email, sender_password)\n",
    "    server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "    print(f\"Email sent to {receiver_email}\")\n",
    "    server.quit()  # Close the connection\n",
    "except Exception as e:\n",
    "    print(f\"Failed to send email to {receiver_email}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1740d-bf81-4955-933b-ec7c25376bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b271eb7-b034-42a8-8a90-2b926ac26094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d916e3-4792-44f4-8fef-dec146c80435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
